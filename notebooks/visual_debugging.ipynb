{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b256f7fc-bab5-492c-8972-3cfb62365f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import importlib\n",
    "import requests\n",
    "import time\n",
    "import subprocess\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import llava\n",
    "import pandas as pd\n",
    "\n",
    "from llava.model import *\n",
    "from torch.nn import functional as F\n",
    "from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN\n",
    "from llava.conversation import conv_templates, SeparatorStyle\n",
    "from llava.eval.run_llava import load_image\n",
    "from llava.model.language_model.llava_llama import LlavaLlamaForCausalLM\n",
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.utils import disable_torch_init\n",
    "from llava.mm_utils import process_images, tokenizer_image_token, get_model_name_from_path\n",
    "from transformers.generation.streamers import TextIteratorStreamer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig, BitsAndBytesConfig\n",
    "from llava.serve.baristia_utils import  load_image_processor\n",
    "from peft import PeftModel, get_peft_model, PeftConfig\n",
    "\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from transformers import LlamaConfig\n",
    "from llava.serve.barista import LoraInferenceService\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from threading import Thread\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "\n",
    "%matplotlib inline\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254e63d8-ba9d-480a-b28d-61b708cc1ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e49032-82c7-4724-b52f-ad423db72de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_weights(net1, net2):\n",
    "    idx = 0\n",
    "    for param1, param2 in zip(net1.parameters(), net2.parameters()):\n",
    "        idx += 1\n",
    "        if not torch.equal(param1.data, param2.data):\n",
    "            print(\"Weights are not equal.\")\n",
    "            return False\n",
    "\n",
    "    print(f'All {idx} layers are equal.')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac67b55-a699-474c-b0bc-c4b2ea61d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_model_path = \"liuhaotian/llava-v1.5-7b\"\n",
    "lora_model_path = '../checkpoints/llava-v1.5-7b-augmented-roastme-lora-13000-4-epochs'\n",
    "model_path = reference_model_path\n",
    "load_8bit=False\n",
    "load_4bit=False\n",
    "device='cuda'\n",
    "device_map=\"auto\"\n",
    "use_flash_attn=False\n",
    "torch_dtype=torch.bfloat16\n",
    "kwargs = {\n",
    "    'torch_dtype': torch_dtype,\n",
    "    'device_map': device_map,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ef5ecf-20ff-4bf0-9bc9-00877fd3a76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Path to folder that contains adapter_config.json and the associated .bin files for the Peft model\n",
    "adapters_name = lora_model_path\n",
    "\n",
    "# Get PeftConfig from the finetuned Peft Model. This config file contains the path to the base model\n",
    "peft_config = PeftConfig.from_pretrained(adapters_name)\n",
    "\n",
    "# W/out this no vision tower?\n",
    "lora_cfg_pretrained = LlavaConfig.from_pretrained(peft_config.base_model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be258f6-35cf-4a62-861c-003725e74eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path, use_fast=False)\n",
    "model = LlavaLlamaForCausalLM.from_pretrained(peft_config.base_model_name_or_path, low_cpu_mem_usage=True, config=lora_cfg_pretrained, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6338ec7-62a8-4258-b5fc-99452f4bfe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = LlavaLlamaForCausalLM.from_pretrained(peft_config.base_model_name_or_path, low_cpu_mem_usage=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3581aa36-7a6e-456a-9b32-a59f82641034",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_with_lora = PeftModel.from_pretrained(model=model, model_id=lora_model_path, adapter_name=\"test_lora\", torch_dtype=torch.bfloat16, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b412b5-3fda-4d36-a697-6a77675147cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_weights(model, peft_model_with_lora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fc371e-bb1b-4e40-bb89-e360680b2271",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_1 = [p for p in model.parameters()]\n",
    "parameters_2 = [p for p in peft_model_with_lora.parameters()]\n",
    "print(len([p.shape for p in parameters_1]))\n",
    "len([p.shape for p in parameters_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731cc308-aa99-435a-93bc-fe2cf3bc821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c262b772-2013-428f-afd8-c86a6fb237e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[x for x in base_model.children()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373d4a98-8612-4743-9f72-c8d2cc96a062",
   "metadata": {},
   "outputs": [],
   "source": [
    "[type(layer) for layer in base_model.modules() if \"torch.nn.modules.activation\" in str(type(layer))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f008aea1-7c2b-4773-ad66-1fe8b473603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[layer for layer in base_model.modules() if isinstance(layer, nn.ReLU) or isinstance(layer, nn.Sigmoid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418022a2-e9ec-480d-ac33-fdde7896661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_parameters = [p for p in base_model.modules()]\n",
    "base_model_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee69ecf-430c-4957-841a-f679fb24e7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_functions = (nn.ReLU, nn.Sigmoid, nn.SiLU, nn.GELU)\n",
    "# activation_layers = [(idx, layer) for idx, layer in enumerate(base_model.modules()) if isinstance(layer, activation_functions)]\n",
    "activation_layers = [(idx, layer.__class__) for idx, layer in enumerate(base_model.modules())]\n",
    "print(len([p.shape for p in base_model.parameters()]))\n",
    "len(activation_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b793e880-075d-4ef1-b64a-c7e4a92a40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = activation_layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb757a0-6653-40b2-ac35-090721594dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "[p for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71988240-d56b-4890-804e-e216c25ca16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in base_model.modules():\n",
    "    # print(m)\n",
    "    # print(len([p for p in m.parameters()]))\n",
    "    # print(\"-----\")\n",
    "\n",
    "    if isinstance(m, activation_functions):\n",
    "        print(m)\n",
    "        print([p for p in m.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366acacf-4586-4fd9-bd37-517d93ce6176",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dc5f9a29-7e64-46a8-ba68-27222bffbc61",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'from'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/llava/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'from'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../dataset/augmented/full_dataset.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Display the DataFrame\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfrom\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/envs/llava/lib/python3.10/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/envs/llava/lib/python3.10/site-packages/pandas/core/indexes/base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3807\u001b[0m     ):\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'from'"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"../dataset/augmented/full_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "630876c0-bec0-49cc-aeeb-381b426cf334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9119"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'].apply(len).idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ea7c1091-2762-4bd3-b4cb-832cf589ae1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                 1abgte5_kjnfv4v\n",
       "title                                                            ü§å\n",
       "image            /home/devonperoutky/LLaVA/dataset/images/1abgt...\n",
       "comment_id                                                 kjnfv4v\n",
       "conversations    [{'from': 'human', 'value': '<image>\n",
       "ü§å. Write ...\n",
       "submission_id                                              1abgte5\n",
       "Name: 9119, dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[9119]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9121349e-d16f-435a-b154-de087948f790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'from': 'human', 'value': '<image>\\nü§å. Write an insult about this person.'},\n",
       " {'from': 'gpt',\n",
       "  'value': \"OP's Bio:  ---  >Dia dhaoibh (Hello Everyone)  >I'm Twisted 29 From Ireland, My past times consists of Gaming, Watching Anime, Studying Cyber security and outside of those I like wild water swimming, hiking, the outdoors, space and some Mary Jane.  > >Favourite Video Game - Skyrim >Favourite Book - The Hobbit  >Favourite Movies Top 3 >- Lotr Trilogy >- The Moulin Rouge  >- Dead Poet Society > >Music ( everything ) >Seriously I could go from Beethoven to I Prevail to Ti√´sto to Conway Twitty real quick. > >Hot Take >Feminism has been hijacked by woke, brainwashed Pawns and has ruined the Western World and Womens Rights and Morals.  --- If you think this bio helped you roast, upvote this comment. If you think it doesn‚Äôt, downvote it. If you‚Äôre not sure, leave it to others to decide.\"}]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[9119]['conversations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b74e97f8-5492-4f14-b312-5cc7d8ce73b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OP's Bio:  ---  >Dia dhaoibh (Hello Everyone)  >I'm Twisted 29 From Ireland, My past times consists of Gaming, Watching Anime, Studying Cyber security and outside of those I like wild water swimming, hiking, the outdoors, space and some Mary Jane.  > >Favourite Video Game - Skyrim >Favourite Book - The Hobbit  >Favourite Movies Top 3 >- Lotr Trilogy >- The Moulin Rouge  >- Dead Poet Society > >Music ( everything ) >Seriously I could go from Beethoven to I Prevail to Ti√´sto to Conway Twitty real quick. > >Hot Take >Feminism has been hijacked by woke, brainwashed Pawns and has ruined the Western World and Womens Rights and Morals.  --- If you think this bio helped you roast, upvote this comment. If you think it doesn‚Äôt, downvote it. If you‚Äôre not sure, leave it to others to decide.\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[9119]['conversations'][1]['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ce355fb1-1219-4caf-9c9b-6cf1d3ac5418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         You'll never outrun those roots.\n",
       "1        I don‚Äôt think the voices in your head will be ...\n",
       "2        OP's Bio:  ---  >i once hooked up with someone...\n",
       "3        Eternally single? Don't worry I think I found ...\n",
       "4        You look like the girls on the STD posters at ...\n",
       "                               ...                        \n",
       "19793                     Make dental hygiene great again.\n",
       "19794    The first person in history to receive a full ...\n",
       "19795    This is what happens when you ban abortions in...\n",
       "19796    You strike me as a person who looks up and dow...\n",
       "19797    After reading these comments he‚Äôs gonna stomp ...\n",
       "Name: conversations, Length: 19798, dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['conversations'].apply(lambda x: x[1]['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9a231d8b-ed6d-4972-bb96-e3d8e2d45cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>image</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>conversations</th>\n",
       "      <th>submission_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18396</th>\n",
       "      <td>lhitpa_gmylqmn</td>\n",
       "      <td>Just 2,5 years between both pictures .. what h...</td>\n",
       "      <td>/home/devonperoutky/LLaVA/dataset/images/lhitp...</td>\n",
       "      <td>gmylqmn</td>\n",
       "      <td>[{'from': 'human', 'value': '&lt;image&gt;\n",
       "Just 2,5 ...</td>\n",
       "      <td>lhitpa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                              title  \\\n",
       "18396  lhitpa_gmylqmn  Just 2,5 years between both pictures .. what h...   \n",
       "\n",
       "                                                   image comment_id  \\\n",
       "18396  /home/devonperoutky/LLaVA/dataset/images/lhitp...    gmylqmn   \n",
       "\n",
       "                                           conversations submission_id  \n",
       "18396  [{'from': 'human', 'value': '<image>\n",
       "Just 2,5 ...        lhitpa  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = df['conversations'].apply(lambda x: len(x[1]['value']) > 3000)\n",
    "df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "df52865a-6d5c-46f6-a5a5-31e90a19817a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'from': 'human',\n",
       "  'value': '<image>\\nJust 2,5 years between both pictures .. what happend to me .. roast me! Write an insult about this person.'},\n",
       " {'from': 'gpt',\n",
       "  'value': 'You look like someone who has been carrying a heavy mental load on their back for their entire life. There‚Äôs stress and a heaviness in your eyes even in your first picture, OP.   Other commenters shared a link to another post you made, OP. As someone who has also struggled through childhood trauma, please know that therapy and trauma work based around CPTSD has been monumentally helpful for me.   If therapy isn‚Äôt an option right now, I can recommend some books and subreddits. It‚Äôs morbidly comforting knowing how many others can relate‚Äîto not feel alone with the struggles of trauma.   CPTSD: From Surviving to Thriving by Pete Walker (this book helped me put into context the lasting affects trauma had on me. I realized my brain was reacting in a way to protect itself and how it‚Äôs still using the same system to ‚Äútry to keep me safe‚Äù now as an adult.   The Body Keeps the Score by Bessel Van der Kolk (this book helped me understand why I developed fibromyalgia and why I hold so much tension. Why my body would react in certain ways aka panic attack when I *thought* there was nothing bothering me)  Understanding the Borderline Mother by Christine Ann Lawson (I haven‚Äôt read this one personally but a lot of commenters on r/raisedbyborderlines have felt validated by reading this)   Running on Empty by Christine Musello and Jonice Webb (this book maps out about a dozen different circumstances in which a parent‚Äôs over-action, negligence, smothering, etc lead to internalized trauma that can well...leave you feeling running on empty all the time. Many times it‚Äôs not just one example but the parent checking off many examples. Having the cause and effect laid out clearly like this helped me again reinforce that my trauma is not my fault)   Hold Me Tight by Sue Johnson (I haven‚Äôt read this one personally but my therapist has recommended it to me. She said it focuses on attachment styles. Our upbringing affects how we later form relationships with others. If it was unstable growing up, it may be difficult to form stable relationships as an adult. I for one can certainly agree with how accurate this is)  I‚Äôm 27 this year, OP. You‚Äôre only a few years older than me. We‚Äôre both young and we both have our lives ahead of us. The future is uncertain, but you‚Äôre not moving forward in it alone.   I‚Äôm so sorry your past was not your own. Give yourself the space and time to grieve that‚Äîit‚Äôs more than valid. I believe in your resiliency, OP. I believe you can accomplish your goals. I have a feeling you‚Äôre feeling a lot like Atlas or Sisyphus right now with the pain you‚Äôre carrying.   It‚Äôs okay, you can rest, mend, and eventually the boulders will become smaller and smaller once you chip away at them. Eventually the boulder will become a big rock that might need help lifting from a friend. Eventually the big rock will become a heavy stone that will tire you, but you worked on practicing healthy lifting forms and knowing when to take breaks for yourself. And eventually the the heavy stone will become something manageable. It might take the form of a small pebble in your shoe that keeps popping back up. But it‚Äôs okay, you‚Äôve worked on recognizing on when you‚Äôll need to bring tools for the big rocks or boulders, when you can recognize when you‚Äôre lifting the heavy stone so you know when to put it down, and how to take the pebbles out of your shoes without losing your shoe too.   I believe in you OP. I hope you can believe in yourself, too.   r/raisedbyborderlines r/raisedbynarcissists r/cptsd r/narcissisticparents r/justnofamily have been cathartic subreddits to visit and see the other commenters who also share my life experiences. Knowing I wasn‚Äôt alone in my experiences saved my life. I celebrated my 25th birthday in 2019 in an intensive outpatient therapy center (and a cumulative 42 hours that week in group therapy) because I was suicidal. It can get better, I promise.'}]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[18396]['conversations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8b73dd11-96a5-4e0a-976c-f3d3d9a58f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'from': 'human',\n",
       "  'value': '<image>\\n40 years old, wife walked out 2 years ago, stoner, 100k in credit debt, lives with parents in a retirement mobile home community, in love with a new girl who doesn‚Äôt like me back. On the bright side, I have a full time job, I travel the world and will be pursuing stand-up comedy in 2024. Destroy me! Write an insult about this person.'},\n",
       " {'from': 'gpt', 'value': '40?!? When?? In 1992?'}]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[7941]['conversations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a66e28-3dbb-4019-81ca-3ac0e97672cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
